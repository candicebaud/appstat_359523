countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
length <- numeric(length = length(countries))
i = 1
for (country in countries){
data_meth_2 <- data_frame%>%filter(location == country)
m = min(which(data_meth_2$log_total_cases_per_million > 1))
starting_point[i] <- (data_meth_2$date)[m]
length[i] = as.Date('01-11-2020', format = '%d-%m-%Y') - starting_point[i]
i <- i+1
}
i = 1
data_meth_2 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i] )
data_meth_2$time <- 1:length[i]
data_meth_2$time <- (data_meth_2$time - min(data_meth_2$time))/(max(data_meth_2$time) - min(data_meth_2$time))
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i])%>% select(-'date')
data__$time <- 1:length[i]
data__$time <- (data__$time - min(data__$time))/(max(data__$time) - min(data__$time))
data_meth_2 <- rbind(data_meth_2, data__)
i <- i+1
}
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
length <- numeric(length = length(countries))
i = 1
for (country in countries){
data_meth_2 <- data_frame%>%filter(location == country)
m = min(which(data_meth_2$log_total_cases_per_million > 1))
starting_point[i] <- (data_meth_2$date)[m]
length[i] = as.Date('01-11-2020', format = '%d-%m-%Y') - starting_point[i]
i <- i+1
}
i = 1
data_meth_2 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i] )
data_meth_2$time <- 1:length[i]
data_meth_2$time <- (data_meth_2$time - min(data_meth_2$time))/(max(data_meth_2$time) - min(data_meth_2$time))
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i])
data__$time <- 1:length[i]
data__$time <- (data__$time - min(data__$time))/(max(data__$time) - min(data__$time))
data_meth_2 <- rbind(data_meth_2, data__)
i <- i+1
}
rm(data__)
View(data_meth_1)
View(data_meth_2)
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
i = 1
for (country in countries){
data_meth_1 <- data_frame%>%filter(location == country)
m = min(which(data_meth_1$roll_log_cases_per_million > 1))
starting_point[i] <- (data_meth_1$date)[m]
i <- i+1
}
length = as.Date('01-11-2020', format = '%d-%m-%Y') - max(starting_point)
i = 1
data_meth_1 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length ) %>% select(-'date')
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
i = 1
for (country in countries){
data_meth_1 <- data_frame%>%filter(location == country)
m = min(which(data_meth_1$roll_log_cases_per_million > 1))
starting_point[i] <- (data_meth_1$date)[m]
i <- i+1
}
length = as.Date('01-11-2020', format = '%d-%m-%Y') - max(starting_point)
i = 1
data_meth_1 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length )
data_meth_1$time <- 1:length
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length)
data__$time <- 1:length
data_meth_1 <- rbind(data_meth_1, data__)
i <- i+1
}
rm(data__)
#data_ %>% group_by(location) %>% summarise(n = max(time))
data_meth_1 %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line()
data_meth_1 %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line()
data_meth_1 %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line() +ylab('Logarithm of the number of cases per million')
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
length <- numeric(length = length(countries))
i = 1
for (country in countries){
data_meth_2 <- data_frame%>%filter(location == country)
m = min(which(data_meth_2$log_total_cases_per_million > 1))
starting_point[i] <- (data_meth_2$date)[m]
length[i] = as.Date('01-11-2020', format = '%d-%m-%Y') - starting_point[i]
i <- i+1
}
i = 1
data_meth_2 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i] )
data_meth_2$time <- 1:length[i]
data_meth_2$time <- (data_meth_2$time - min(data_meth_2$time))/(max(data_meth_2$time) - min(data_meth_2$time))
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i])
data__$time <- 1:length[i]
data__$time <- (data__$time - min(data__$time))/(max(data__$time) - min(data__$time))
data_meth_2 <- rbind(data_meth_2, data__)
i <- i+1
}
rm(data__)
data_meth_2 %>% group_by(location) %>% ggplot(aes(x=time, y=log_total_cases_per_million, color=location)) + geom_line() + xlab('date') + ylab('Log of the cumulated cases(per million)')
col = c('time', 'log_total_cases_per_million', 'location')
data_pca <- data_meth_2[,col]
data_pca <- pivot_wider(data_pca, names_from = location, values_from = log_total_cases_per_million)
View(data_pca)
my_nodes <- data_meth_2$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.1),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base) %*% B_base) %*% t(B_base) %*% data_meth_2$log_total_cases_per_million
nodes_evaluation = seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.001)
Bplot <-bsplineS(nodes_evaluation, norder = 6, nodes_per_week)
data_smoothed <- Bplot %*% eta_hat
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.1),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
View(data_pca)
library(fda)
my_nodes <- data_meth_2$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.1),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base) %*% B_base) %*% t(B_base) %*% data_meth_2$log_total_cases_per_million
nodes_evaluation = seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.001)
Bplot <-bsplineS(nodes_evaluation, norder = 6, nodes_per_week)
data_smoothed <- Bplot %*% eta_hat
View(smoothed)
data_smoothed
View(data_meth_1)
col = c('time', 'roll_log_cases_per_million', 'location')
data_pca <- data_meth_1[,col]
data_pca <- pivot_wider(data_pca, names_from = location, values_from = roll_log_cases_per_million)
#gg_miss_fct(x = data_pca, fct = time)
#remove missing data if any
data_pca <- na.omit(data_pca)
data_pca <- data_pca[,2:length(data_pca)]
matrix_pca <- data.matrix(data_pca)
X = t(matrix_pca)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
X = t(matrix_pca)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
col = c('time', 'log_total_cases_per_million', 'location')
data_pca <- data_meth_2[,col]
data_pca <- pivot_wider(data_pca, names_from = location, values_from = log_total_cases_per_million)
gg_miss_fct(x = data_pca, fct = time)
gg_miss_fct(x = data_pca, fct = location)
View(data_pca)
col = c('time', 'log_total_cases_per_million', 'location')
data_pca <- data_meth_2[,col]
gg_miss_fct(x = data_pca, fct = location)
gg_miss_fct(x = data_pca, fct = time) #pas de données manquantes
gg_miss_fct(x = data_pca, fct = location) #pas de données manquantes
View(data_pca)
data_pca <- pivot_wider(data_pca, names_from = location, values_from = log_total_cases_per_million)
View(data_pca)
gg_miss_fct(x = data_pca, fct = albania) #pas de données manquantes
View(data_meth_2)
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
length <- numeric(length = length(countries))
i = 1
for (country in countries){
data_meth_2 <- data_frame%>%filter(location == country)
m = min(which(data_meth_2$log_total_cases_per_million > 1))
starting_point[i] <- (data_meth_2$date)[m]
length[i] = as.Date('01-11-2020', format = '%d-%m-%Y') - starting_point[i]
i <- i+1
}
i = 1
data_meth_2 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i] )
data_meth_2$time <- 1:length[i]
#data_meth_2$time <- (data_meth_2$time - min(data_meth_2$time))/(max(data_meth_2$time) - min(data_meth_2$time))
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i])
data__$time <- 1:length[i]
#data__$time <- (data__$time - min(data__$time))/(max(data__$time) - min(data__$time))
data_meth_2 <- rbind(data_meth_2, data__)
i <- i+1
}
rm(data__)
View(data_meth_2)
col = c('time', 'log_total_cases_per_million', 'location')
data_pca <- data_meth_2[,col]
gg_miss_fct(x = data_pca, fct = location) #pas de données manquantes
data_pca <- pivot_wider(data_pca, names_from = location, values_from = log_total_cases_per_million)
View(data_pca)
#remove missing data if any
data_pca <- na.omit(data_pca)
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 7),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base) %*% B_base) %*% t(B_base) %*% data_meth_2$log_total_cases_per_million
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 7),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base) %*% B_base) %*% t(B_base) %*% data_meth_2$log_total_cases_per_million
eta_hat <- ginv(t(B_base) %*% B_base) %*% t(B_base) %*% data_pca
eta_hat <- t(B_base)%*% B_base)%*%t(B_base)%*%data_pca
eta_hat <- (t(B_base)%*% B_base)%*%t(B_base)%*%data_pca
eta_hat <- ginv(t(B_base)%*% B_base)%*%t(B_base)%*%data_pca
ginv(t(B_base)%*% B_base)
t(B_base)%*%data_pca
matrix_pca <- data.matrix(data_pca)
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 7),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base)%*% B_base)%*%t(B_base)%*%data_pca
my_nodes <- matrix_pca$time
eta_hat <- ginv(t(B_base)%*% B_base)%*%t(B_base)%*%matrix_pca
matrix_pca <- data.matrix(data_pca)
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 7),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base)%*% B_base)%*%t(B_base)%*%matrix_pca
nodes_evaluation = seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.1)
Bplot <-bsplineS(nodes_evaluation, norder = 6, nodes_per_week)
data_smoothed <- Bplot %*% eta_hat
data_smoothed
data_smoothed[,1]
plot(data_smoothed[,1])
data_smoothed[,2]
plot(data_smoothed[,2])
View(data_smoothed)
data_smoothed %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line() +ylab('Logarithm of the number of cases per million')
dim(smoothed_data)
dim(data_smoothed)
plot(nodes_evaluation, data_smoothed[,2], type = 'l')
for (n in 1:dim(data_smoothed)[2]){
lines(nodes_evaluation, data_smoothed[,n])
}
pivot_longer(data_smoothed, names_to = colnames(smoothed_data[2:length(smoothed_data)]))
pivot_longer(data_smoothed, names_to = location)
pivot_longer(data_smoothed, names_to = location)
countries
pivot_longer(data_smoothed, cols = countries, names_to = location)
countries
pivot_longer(data_smoothed, cols = unique(countries), names_to = location)
pivot_longer(data_smoothed[,2:41], cols = unique(countries), names_to = location)
unique(countries)
pivot_longer(data_smoothed, cols = c('Albania', 'France'), names_to = location)
View(data_smoothed)
pivot_longer(data_smoothed, cols = 'Albania', names_to = location)
pivot_longer(data_smoothed, cols = 'Albania', names_to = 'location')
plot(nodes_evaluation, data_smoothed[,2], type = 'l')
for (n in 1:dim(data_smoothed)[2]){
lines(nodes_evaluation, data_smoothed[,n])
}
X = t(data_smoothed)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
X = t(data_smoothed[,2:length(data_smoothed)])
X = t(data_smoothed[,2:length(data_smoothed)[2]])
col <- countries
data_smoothed <- data_smoothed[,col]
View(data_smoothed)
col <- countries
data_smoothed <- data_smoothed[,col]
X = t(data_smoothed)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
lapply(c("dplyr","chron","ggplot2","tidyr","questionr","survival","forcats","tidyselect",
"data.table","table1","lubridate", "ggpubr","viridis","finalfit","survminer",
"ggpubr", "ggthemes", "gridExtra", "rstatix","stringr",
"wesanderson","kableExtra", "naniar","boot","scales","ggsci", "stringr",
"Hmisc","DescTools","swimplot", 'stats', 'EnvStats', 'finalfit'),
library, character.only=TRUE)
set.seed(435) #set the seed for reproducible results
data <- read.csv('owid-covid-data.csv', header = T)
data <- data %>% filter(continent == 'Europe')
#gg_miss_fct(x = data, fct = location)#to see where data is missing
forbidden <- c('England', 'Scotland', 'Northern Ireland', 'Wales')
data <- subset(data, !(data$location %in% forbidden))
variables_to_keep <- c('location', 'date', 'total_cases', 'new_cases', 'total_cases_per_million', 'new_cases_per_million', 'stringency_index', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index', 'population', 'excess_mortality_cumulative_absolute', 'excess_mortality', 'excess_mortality_cumulative_per_million', 'excess_mortality_cumulative')
df <- data[,variables_to_keep]
#gg_miss_fct(x = df, fct = location)
#some countries still have lots of missing data so we don't take them
forbidden <- c('Andorra', 'Faeroe Islands', 'Gibraltar', 'Guernsey', 'Isle of Man', 'Jersey', 'Kosovo', 'Liechtenstein', 'Monaco', 'San Marino', 'Vatican')
df <- subset(df, !(df$location %in% forbidden)) #the data is way better
df <- df %>% mutate(date = as.Date(date, format = "%Y-%m-%d"))
#write.csv(df, "C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_6\\data_processed.csv", row.names=FALSE)
#df <- read.csv('data_processed.csv', header = T)
df <- df %>% mutate(
log_total_cases = log(total_cases),
log_total_cases_per_million = log(total_cases_per_million)
)
df%>% ggplot(aes(x=date, y=log_total_cases_per_million, color=location)) + geom_line() + xlab('date') + ylab('Log of the cumulated cases(per million)')
df%>% ggplot(aes(x=date, y=new_cases_per_million, color=location)) + geom_line() + xlab('date') + ylab('New cases per million')
library(cowplot)
library(zoo)
#roll <- rollmean(df$log_total_cases_per_million, k=7, align = 'right', fill = NA)
countries <- unique(df$location)
test <- df %>% filter(location == countries[1])
smoothed = rollmean(test$log_total_cases_per_million, k=7, align = 'right', fill = NA)
test$roll_log_cases_per_million <- smoothed
smoothed = rollmean(test$new_cases_per_million, k=7, align = 'right', fill = NA)
test$roll_new_cases_per_million <- smoothed
data_frame <- test
countries <- countries[2:length(countries)]
for (country in countries){
test <- df %>% filter(location == country)
smoothed = rollmean(test$log_total_cases_per_million, k=7, align = 'right', fill = NA)
test$roll_log_cases_per_million <- smoothed
smoothed = rollmean(test$new_cases_per_million, k=7, align = 'right', fill = NA)
test$roll_new_cases_per_million <- smoothed
data_frame <- bind_rows(data_frame,test)
}
df <- df %>% mutate(
roll_log_cases_per_million = data_frame$roll_log_cases_per_million,
roll_new_cases_per_million = data_frame$roll_new_cases_per_million
)
df%>% ggplot(aes(x=date, y=roll_log_cases_per_million, color=location)) + geom_line()
df%>% ggplot(aes(x=date, y=roll_new_cases_per_million, color=location)) + geom_line()
countries <- unique(df$location)
#calcule le smoothed pour chaque
test <- df %>% filter(location == countries[1])
smoothed = ksmooth(test$date, test$total_cases_per_million, bandwidth = 7, kernel = 'normal')
test$smoothed_cases_per_million <- smoothed$y
smoothed = ksmooth(test$date, test$log_total_cases_per_million, bandwidth = 7)
test$log_smoothed_cases_per_million <- smoothed$y
data_frame <- test
countries <- countries[2:length(countries)]
for (country in countries){
test <- df %>% filter(location == country)
smoothed = ksmooth(test$date, test$total_cases, bandwidth = 7)
test$smoothed_cases_per_million <- smoothed$y
smoothed = ksmooth(test$date, test$log_total_cases_per_million, bandwidth = 7)
test$log_smoothed_cases_per_million <- smoothed$y
data_frame <- bind_rows(data_frame,test)
}
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
i = 1
for (country in countries){
data_meth_1 <- data_frame%>%filter(location == country)
m = min(which(data_meth_1$roll_log_cases_per_million > 1))
starting_point[i] <- (data_meth_1$date)[m]
i <- i+1
}
length = as.Date('01-07-2021', format = '%d-%m-%Y') - max(starting_point)
i = 1
data_meth_1 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length )
data_meth_1$time <- 1:length
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length)
data__$time <- 1:length
data_meth_1 <- rbind(data_meth_1, data__)
i <- i+1
}
rm(data__)
#data_ %>% group_by(location) %>% summarise(n = max(time))
data_meth_1 %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line()
data_meth_1 %>% group_by(location) %>% ggplot(aes(x=time, y=roll_log_cases_per_million, color=location)) + geom_line() +ylab('Logarithm of the number of cases per million')
countries <- unique(data_frame$location)
starting_point <- as.Date(numeric(length = length(countries)))
length <- numeric(length = length(countries))
i = 1
for (country in countries){
data_meth_2 <- data_frame%>%filter(location == country)
m = min(which(data_meth_2$log_total_cases_per_million > 1))
starting_point[i] <- (data_meth_2$date)[m]
length[i] = as.Date('01-07-2021', format = '%d-%m-%Y') - starting_point[i]
i <- i+1
}
i = 1
data_meth_2 <- data_frame%>%filter(location == 'Albania') %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i] )
data_meth_2$time <- 1:length[i]
#data_meth_2$time <- (data_meth_2$time - min(data_meth_2$time))/(max(data_meth_2$time) - min(data_meth_2$time))
i = 2
for (country in countries[2:length(countries)]){
data__ <- data_frame%>%filter(location == country) %>% filter(date >= starting_point[i]) %>% filter(date < starting_point[i] + length[i])
data__$time <- 1:length[i]
#data__$time <- (data__$time - min(data__$time))/(max(data__$time) - min(data__$time))
data_meth_2 <- rbind(data_meth_2, data__)
i <- i+1
}
rm(data__)
library(fda)
col = c('time', 'log_total_cases_per_million', 'location')
data_pca <- data_meth_2[,col]
gg_miss_fct(x = data_pca, fct = location) #pas de données manquantes
data_pca <- pivot_wider(data_pca, names_from = location, values_from = log_total_cases_per_million)
#remove missing data if any
data_pca <- na.omit(data_pca)
#data_pca <- data_pca[,2:length(data_pca)]
matrix_pca <- data.matrix(data_pca)
my_nodes <- data_pca$time
nodes_per_week <- c(my_nodes[1], seq(range(my_nodes)[1], range(my_nodes)[2], by = 7),
my_nodes[length(my_nodes)])
B_base <- bsplineS(my_nodes, norder = 6, nodes_per_week)
eta_hat <- ginv(t(B_base)%*% B_base)%*%t(B_base)%*%matrix_pca
nodes_evaluation = seq(range(my_nodes)[1], range(my_nodes)[2], by = 0.1)
Bplot <-bsplineS(nodes_evaluation, norder = 6, nodes_per_week)
data_smoothed <- Bplot %*% eta_hat
#pivot_longer(data_smoothed, cols = 'Albania', names_to = 'location')
plot(nodes_evaluation, data_smoothed[,2], type = 'l')
for (n in 1:dim(data_smoothed)[2]){
lines(nodes_evaluation, data_smoothed[,n])
}
col = c('time', 'roll_log_cases_per_million', 'location')
data_pca <- data_meth_1[,col]
data_pca <- pivot_wider(data_pca, names_from = location, values_from = roll_log_cases_per_million)
#gg_miss_fct(x = data_pca, fct = time)
#remove missing data if any
data_pca <- na.omit(data_pca)
data_pca <- data_pca[,2:length(data_pca)]
matrix_pca <- data.matrix(data_pca)
X = t(matrix_pca)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
col <- countries
data_smoothed <- data_smoothed[,col]
X = t(data_smoothed)
mu <- colMeans(X)
X <- sweep(X,2,mu)
SVD <- svd(X)
Scores <- SVD$u %*% diag(SVD$d)
Loadings <- SVD$v
FVE <- SVD$d^2/sum(SVD$d^2)
par(mfrow = c(3,2))
plot(X[1,]+mu,type="l", ylim=range(X+mu), main="Data and the mean", ylab = '')
for(n in 1:dim(X)[1]) points(X[n,]+mu,type="l")
points(mu,col=2,lwd=2,type="l")
plot(Scores[1,]*sign(sum(Loadings[,1])), Scores[2,]*sign(sum(Loadings[,2])), main="1st vs 2nd PC scores", ylab = '', xlab ='')
plot(Loadings[,1]*sign(sum(Loadings[,1])),type="l", main=paste0("1st PC (",round(100*FVE[1])," % of var)"), ylab = '')
plot(Loadings[,2]*sign(sum(Loadings[,2])),type="l", main=paste0("2nd PC (",round(100*FVE[2])," % of var)"), ylab = '')
plot(Loadings[,3]*sign(sum(Loadings[,3])),type="l", main=paste0("3rd PC (",round(100*FVE[3])," % of var)"), ylab = '')
plot(Loadings[,4]*sign(sum(Loadings[,4])),type="l", main=paste0("4th PC (",round(100*FVE[4])," % of var)"), ylab = '')
