---
title: "Report Project 2"
author: "Sciper 359523"
date: "2023-03-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r working directory and data, echo=FALSE, include=FALSE}
lapply(c("dplyr","chron","ggplot2","tidyr","questionr","survival","forcats","tidyselect",
         "data.table","table1","lubridate", "ggpubr","viridis","finalfit","survminer",
         "ggpubr", "ggthemes", "gridExtra", "rstatix","stringr",
         "wesanderson","kableExtra", "naniar","boot","scales","ggsci", "stringr",
         "Hmisc","DescTools","swimplot", 'stats', 'EnvStats', 'finalfit'), 
       library, character.only=TRUE)

Sys.setlocale("LC_TIME", "English")
load("2_online_shopping.RData")
set.seed(435) #set the seed for reproducible results
```

# 1. Introduction 
In today's data-driven world, businesses are constantly seeking new ways to leverage customer data to make informed decisions and drive growth[1]. One area where data analysis can prove particularly useful is in forecasting customer purchases. By analyzing data on user behavior and purchase history, businesses can gain insights into what products or services customers are likely to buy in the future. Users' reactions are therefore scrutinized to improve sales by better tailoring the ads. 

In this report, we work with a data set providing us several variable such as an outcome variable we want to model, which is a binary indicator of a purchase being made or not. The other variables, that will help build the model are mostly divided between the users' actions recorded by the websites, and the user's personal characteristics.    

In this report, we explore the use of a logistic regression model to predict purchase behavior based on user actions and personal characteristics. Our data set includes several variables, including a binary indicator of whether a purchase was made or not, as well as other user behavior and personal characteristics that serve as predictors. 

The outline of the remainder of this report is as follows. We introduce the data in section 2, describe our model selection procedure in section 3 and present the final model. We analyse our model via the diagnostics in Section 4 and will compare it to other in section 5. In section 6, we analyze the model built, and we'll conclude in section 7.


# 2. Data characteristics
The outcome of interest is the fact that a purchase was made or not (variable *purchase*). The data set is composed of several different features that can be decomposed in three main groups :

1. Data coming from the e-commerce website :
+ The number of administrative-type pages that the user visited and the time spent on them (numerical variable)
+ The number of informational-type pages that the user visited and the time spent on them (numerical variable)
+ The number of product-related-type pages that the user visited and the time spent on them (numerical variable)

2. Data derived from the date :
+ The month in which the session took place (categorical variable with 10 levels)
+ An indicator of whether the session took place during the week-end or not (dummy variable)
+ An indicator between [0,1] evaluating the closeness to a special day (numerical variable)

3. Data coming from Google Analytics :
+ The average bounce rate of pages visited (numerical variable)
+ The average exit rate of pages visited (numerical variable)
+ The average page value of pages visited (numerical variable)
+ The operating systems of the user (categorical variable with 8 levels)
+ The web browsers of the users (categorical variable with 13 levels)
+ The geographic region in which the use is located (categorical variable with 9 levels)
+ Where from the user arrived at the site (categorical variable with 20 levels)
+ The type of visitor (categorical variable with 3 levels)



```{r data base work, echo=FALSE, include = FALSE}
df<-Data
  
#put everything in order (rename, type of var)
df <- df %>% mutate(
  #from the e-commerce website
  administrative = as.numeric(Administrative) %>% ff_label("Number of administrative pages visited"),
  administrative_duration = as.numeric(Administrative_Duration)%>% ff_label("Time spent on administrative pages"),
  informational = as.numeric(Informational) %>% ff_label("Number of informational-type pages visited"),
  informational_duration =as.numeric(Informational_Duration) %>% ff_label("Time spent on informational-type pages"),
  product_related = as.numeric(ProductRelated) %>% ff_label("Number of product related type pages visited"),
  product_related_duration = as.numeric(ProductRelated_Duration)%>% ff_label(" Time spent on product related type pages"),
  #derived from a date
  month = as.factor(Month) %>% ff_label("Month of the session"),
  weekend = as.factor(Weekend) %>% ff_label("Indicator of the session during a week-end"),
  special_day = as.numeric(SpecialDay)%>% ff_label("Closeness to a Special day"),
  #from google analytics
  bounce_rates = as.numeric(BounceRates) %>% ff_label("Average bounce rate of pages visited"),
  exit_rates = as.numeric(ExitRates) %>% ff_label('Average exit of pages visited'),
  page_values= as.numeric(PageValues) %>% ff_label('Average page value of pages visited'),
  operating_systems = as.factor(OperatingSystems)%>% ff_label("Operating systems of the user"),
  browser = as.factor(Browser)%>% ff_label("Browser of the user"),
  region = as.factor(Region) %>% ff_label("Geographic region"),
  traffic_type = as.factor(TrafficType)%>% ff_label("Traffic type"),
  visitor_type = as.factor(VisitorType)%>% ff_label("Visitor type"),
  purchase = as.factor(Revenue)%>% ff_label("Indicator of a purchase made or not")
)

df <- df %>% mutate(
  purchase = as.factor(case_when(
    purchase == F ~ 0,
    purchase == T ~ 1
  )))


#final dataframe
df <- df %>% select(purchase,visitor_type,traffic_type,region,browser, operating_systems,page_values, exit_rates, bounce_rates, special_day, weekend, month, product_related_duration, product_related, informational_duration, informational,administrative_duration, administrative)

buy <- 100*(1 - sum(df$purchase==0)/length(df$purchase))
```

The purchases represent `r buy` of the data set, and are at more than 75% done by returning visitors. No region seems to particularly distinguish itself but there are some noticeable tendencies depending on the browser and traffic-type used. Users who buy a product also tend to look at more pages and exit and bounce less early than the ones who don't purchase a product. They tend to spend more time in the web and to inform themselves more. Weekends and special days don't seem to have an effect on the sales which seems surprising. However, the session month seems to have a non-neglictable influence. 

Some variables are greatly overdispersed, so we decide to transform them to be able to construct better models. We apply both log transformations and square root transformation to solve this issue.

```{r adding variables, echo=FALSE, include = FALSE}
#log transformations
df <- df %>% mutate(
  log_exit = log(exit_rates +1 ),
  log_bounce = log(bounce_rates +1),
  log_administrative = log(administrative +1),
  log_admin_duration = log(administrative_duration +1),
  log_prod_related_duration = log(product_related_duration +1),
  log_prod_related = log(product_related +1),
  log_inf_duration = log(informational_duration+1),
  log_inf = log(informational_duration +1),
  log_page_values = log(page_values +1)
)

#sqrt transformation
df <- df %>% mutate(
  sqrt_exit = sqrt(exit_rates),
  sqrt_bounce = sqrt(bounce_rates),
  sqrt_administrative = sqrt(administrative),
  sqrt_time_admin = sqrt(administrative_duration),
  sqrt_time_duration = sqrt(product_related_duration)
)

#interaction terms
df <- df %>% mutate(
  inter_product = product_related * product_related_duration,
  inter_informational = informational * informational_duration,
  inter_admin = administrative * administrative_duration
)
```



# 3. Model selection 

```{r model building, echo=FALSE, include = FALSE}
m0_0 <- glm(purchase ~visitor_type + traffic_type + region + browser + operating_systems + page_values + exit_rates + bounce_rates + special_day + weekend + month + product_related_duration + product_related + informational_duration + informational + administrative_duration + administrative, family = 'binomial', data = df) #without the new included variables 

m0 <- glm(purchase ~., family = 'binomial', data = df) #with all the variables, including the new ones 

#to compare the first two models
summary(m0_0)
summary(m0)

m0_0$aic
m0$aic

m0_0$deviance
m0$deviance #adding the variables improved both the AIC and the deviance


#now I build a better model with the function stepAIC which will select the best model in terms of AIC
library('MASS')
#model <- stepAIC(m0,direction = c("both", "backward", "forward"), trace = FALSE)

model <-glm(formula = purchase ~ visitor_type + traffic_type + page_values + 
    exit_rates + bounce_rates + month + product_related_duration + 
    product_related + administrative + log_administrative + log_admin_duration + 
    log_prod_related_duration + log_page_values + sqrt_exit + 
    sqrt_bounce + sqrt_administrative + sqrt_time_admin + sqrt_time_duration,  family = "binomial", data = df) #this is the model given by stepAIC but as it's very long, I include it here directly

summary(model)

#to see if the variables selected are statistically significative
#Anova(m0, type = 'II', test ='LR')
Anova(model, type = 'II', test ='LR') #product_related and log_administrative are not statistically significant
 

#new model 
improved_model <- glm(formula = purchase ~ visitor_type + traffic_type + page_values + exit_rates + bounce_rates + month + product_related_duration + 
     administrative +  log_admin_duration + 
    log_prod_related_duration + log_page_values + sqrt_exit + 
    sqrt_bounce + sqrt_administrative + sqrt_time_admin + sqrt_time_duration,  family = "binomial", data = df)
summary(improved_model)
Anova(improved_model, type = 'II', test ='LR') #sqrt_time_admin is not significant

#by removing non significative variables one by one, I obtain the final model below
improved_model_2 <- glm(formula = purchase ~ visitor_type + traffic_type + page_values + exit_rates + bounce_rates + month + product_related_duration + 
     administrative  + 
    log_prod_related_duration + log_page_values + sqrt_exit + 
    sqrt_bounce  + sqrt_time_duration,  family = "binomial", data = df)
summary(improved_model_2)
anova_table <- Anova(improved_model_2, type = 'II', test ='LR') #with this one all the variables are significative under the 5%

#odds ratio and confidence intervals
table_results_OR <- exp(cbind(OR = coef(improved_model_2), confint(improved_model_2)))
```

To build the model, I start by computing the full model without the added variables and compared it to the one with added variables to assess their relevance. The model with added variables has a smaller AIC (`r m0$aic` compared to `r m0_0$aic`) as well as a smaller deviance (`r m0$deviance` compared to `r m0_0$deviance`) which gives confidence in those new variables.

Then, I used the function *stepAIC* of the MASS package to do AIC-based model selection. This creates a basis model that I then improve by looking at the significance of the variables with the *Anova* command. 

Summary of the final model
```{r, echo=FALSE}
summary(improved_model_2)
```

Odds ratio and confidence intervals
```{r, echo=FALSE}
table_results_OR
```

Anova of the final model
```{r, echo=FALSE}
anova_table
```

# 4. Model diagnostics
to comment
```{r, fig.align="center", fig.cap="Figure: Diagnostics"}
par(mfrow=c(2,2))
plot(improved_model_2)

plot(improved_model_2$fitted.values, improved_model_2$residuals, main = 'residuals')
```

# 5. Model comparison 
```{r, fig.align="center", fig.cap="Figure: ROC curves : initial model without added variables (red), model with variable selection (blue), final model (green)"}
library(pROC)
invisible(plot(roc(df$purchase,
                   fitted(m0_0)),
               col = "red", 
               print.auc = F,
               main = "ROC curves"))
invisible(plot(roc(df$purchase,
                   fitted(model)),
               print.auc = F, 
               col = "blue", 
               add = T))
invisible(plot(roc(df$purchase,
                   fitted(improved_model_2)),
               print.auc = T, 
               col = "green", 
               add = T))
```

put the table with AIC, AUC and deviance 


```{r, echo=FALSE}
#code provided
library(pROC)
AUC_eval <- function(gmodel,Data){
set.seed(517)
Folds <- matrix(sample(1:dim(Data)[1]), ncol=5)
AUC <- rep(0,5)
for(k in 1:5){
train <- Data[-Folds[,k],]
test <- Data[Folds[,k],]
my_gm <- glm(gmodel$formula, family="binomial", data=train)
test_pred <- predict(my_gm, newdata = test, type="response")
AUC[k] <- auc(test$purchase,test_pred)
}
return(mean(AUC))
}

#gm1 <- glm(purchase~., family="binomial", data=Data)
#AUC_eval(improved_model_2,df)

#il y a des problèmes 

```


# 6. Interpretation
statistical significance + practical significance : to do


# 7. Discussion



# References
[1] https://cmr.berkeley.edu/2018/04/facebook-ads/