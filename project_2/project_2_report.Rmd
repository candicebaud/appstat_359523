---
title: "Report Project 2"
author: "Sciper 359523"
date: "2023-03-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r working directory and data, echo=FALSE, include=FALSE}
lapply(c("dplyr","chron","ggplot2","tidyr","questionr","survival","forcats","tidyselect",
         "data.table","table1","lubridate", "ggpubr","viridis","finalfit","survminer",
         "ggpubr", "ggthemes", "gridExtra", "rstatix","stringr",
         "wesanderson","kableExtra", "naniar","boot","scales","ggsci", "stringr",
         "Hmisc","DescTools","swimplot", 'stats', 'EnvStats', 'finalfit'), 
       library, character.only=TRUE)

Sys.setlocale("LC_TIME", "English")
load("2_online_shopping.RData")
set.seed(435) #set the seed for reproducible results
```

# 1. Introduction 
In today's data-driven world, businesses are constantly seeking new ways to leverage customer data to make informed decisions and drive growth[1]. One area where data analysis can prove particularly useful is in forecasting customer purchases. By analyzing data on user behavior and purchase history, businesses can gain insights into what products or services customers are likely to buy in the future. Users' reactions are therefore scrutinized to improve sales by better tailoring the ads. 

In this report, we work with a data set providing us several variable such as an outcome variable we want to model, which is a binary indicator of a purchase being made or not. The other variables, that will help build the model are mostly divided between the users' actions recorded by the websites, and the user's personal characteristics.    

In this report, we explore the use of a logistic regression model to predict purchase behavior based on user actions and personal characteristics. Our data set includes several variables, including a binary indicator of whether a purchase was made or not, as well as other user behavior and personal characteristics that serve as predictors. 

The outline of the remainder of this report is as follows. We introduce the data in section 2, describe our model selection procedure in section 3 and present the final model. We analyse our model via the diagnostics in Section 4 and will compare it to other in section 5. In section 6 we conclude on the work done and the potential improvements.


# 2. Data characteristics
The outcome of interest is the fact that a purchase was made or not (variable *purchase*). The data set is composed of several different features that can be decomposed in three main groups :

1. Data coming from the e-commerce website :
+ The number of administrative-type pages that the user visited and the time spent on them (numerical variable)
+ The number of informational-type pages that the user visited and the time spent on them (numerical variable)
+ The number of product-related-type pages that the user visited and the time spent on them (numerical variable)

2. Data derived from the date :
+ The month in which the session took place (categorical variable with 10 levels)
+ An indicator of whether the session took place during the week-end or not (dummy variable)
+ An indicator between [0,1] evaluating the closeness to a special day (numerical variable)

3. Data coming from Google Analytics :
+ The average bounce rate of pages visited (numerical variable)
+ The average exit rate of pages visited (numerical variable)
+ The average page value of pages visited (numerical variable)
+ The operating systems of the user (categorical variable with 8 levels)
+ The web browsers of the users (categorical variable with 13 levels)
+ The geographic region in which the use is located (categorical variable with 9 levels)
+ Where from the user arrived at the site (categorical variable with 20 levels)
+ The type of visitor (categorical variable with 3 levels)



```{r data base work, echo=FALSE, include = FALSE}
df<-Data
  
#put everything in order (rename, type of var)
df <- df %>% mutate(
  #from the e-commerce website
  administrative = as.numeric(Administrative) %>% ff_label("Number of administrative pages visited"),
  administrative_duration = as.numeric(Administrative_Duration)%>% ff_label("Time spent on administrative pages"),
  informational = as.numeric(Informational) %>% ff_label("Number of informational-type pages visited"),
  informational_duration =as.numeric(Informational_Duration) %>% ff_label("Time spent on informational-type pages"),
  product_related = as.numeric(ProductRelated) %>% ff_label("Number of product related type pages visited"),
  product_related_duration = as.numeric(ProductRelated_Duration)%>% ff_label(" Time spent on product related type pages"),
  #derived from a date
  month = as.factor(Month) %>% ff_label("Month of the session"),
  weekend = as.factor(Weekend) %>% ff_label("Indicator of the session during a week-end"),
  special_day = as.numeric(SpecialDay)%>% ff_label("Closeness to a Special day"),
  #from google analytics
  bounce_rates = as.numeric(BounceRates) %>% ff_label("Average bounce rate of pages visited"),
  exit_rates = as.numeric(ExitRates) %>% ff_label('Average exit of pages visited'),
  page_values= as.numeric(PageValues) %>% ff_label('Average page value of pages visited'),
  operating_systems = as.factor(OperatingSystems)%>% ff_label("Operating systems of the user"),
  browser = as.factor(Browser)%>% ff_label("Browser of the user"),
  region = as.factor(Region) %>% ff_label("Geographic region"),
  traffic_type = as.factor(TrafficType)%>% ff_label("Traffic type"),
  visitor_type = as.factor(VisitorType)%>% ff_label("Visitor type"),
  purchase = as.factor(Revenue)%>% ff_label("Indicator of a purchase made or not")
)

df <- df %>% mutate(
  purchase = as.factor(case_when(
    purchase == F ~ 0,
    purchase == T ~ 1
  )))


#final dataframe
df <- df %>% select(purchase,visitor_type,traffic_type,region,browser, operating_systems,page_values, exit_rates, bounce_rates, special_day, weekend, month, product_related_duration, product_related, informational_duration, informational,administrative_duration, administrative)

buy <- 100*(1 - sum(df$purchase==0)/length(df$purchase))
```

A first exploratory data analysis enables to display the correlation matrix of *figure 1* in which I only represented the most correlated features with the outcome of interest purchase. The variable page values is the one which is the most correlated with purchase and is also quite correlated with exit rates and bounce rates which are themselves highly correlated. Exit rates is quite correlated with most of the variables displayed in the figure which shows that it is an important feature, heavily linked to the other ones. 

```{r, fig.align="center", fig.cap="Figure 1 : Correlation matrix"}
panel.corrplot <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    Cor <- abs(cor(x, y)) 
    method = "color"
    txt <- paste0(prefix, format(c(Cor, 0.123456789), digits = digits)[1])
    if(missing(cex.cor)) {
        cex.cor <- 0.4 / strwidth(txt)
    }
    text(0.5, 0.5, txt,
         cex = 1 + cex.cor * Cor)
}
panel.hist <- function(x, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5))
    his <- hist(x, plot = FALSE)
    breaks <- his$breaks
    nB <- length(breaks)
    y <- his$counts
    y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = rgb(0, 1, 1, alpha = 0.5), ...)
}


# Plotting the correlation matrix
suppressWarnings(pairs(df$purchase ~ df$page_values + df$exit_rates + df$bounce_rates + df$product_related_duration + df$product_related + df$administrative + df$visitor_type,
      upper.panel = panel.corrplot,   
      lower.panel = panel.smooth, 
      diag.panel = panel.hist,))
```


The purchases in the database represent `r round(buy,digits=1)`% of the data set, and are at more than 75% done by returning visitors. No region seems to particularly distinguish itself but there are some noticeable tendencies depending on the browser and traffic-type used. Users who buy a product also tend to look at more pages and exit and bounce less early than the ones who don't purchase a product. They tend to spend more time in the web and to inform themselves more. Weekends and special days don't seem to have an effect on the sales which seems surprising. However, the session month seems to have a non-neglictable influence. 

Some categorical variables contain few observations for each level so we use clustering to gather levels and fit the model more properly.

```{r clustering, echo=FALSE, include = FALSE}
#for traffic_type
traffic_type <- df$traffic_type
hc <- hclust(dist(table(traffic_type)))
plot(hc)

clusters_traffic_type <- cutree(hc, h = 7)
clusters_traffic_type

df<- df %>% mutate(
  grouped_traffic_type = case_when(
    traffic_type == '1'~ '1',
    traffic_type == '2'~ '2',
    traffic_type == '3'~ '3',
    traffic_type == '4'~ '4',
    traffic_type == '5'~ '5',
    traffic_type == '6'~ '6',
    traffic_type == '7'~ '7',
    traffic_type == '8'~ '8',
    traffic_type == '9'~ '7',
    traffic_type == '10'~ '9',
    traffic_type == '11'~ '10',
    traffic_type == '12'~ '11',
    traffic_type == '13'~ '12',
    traffic_type == '14'~ '11',
    traffic_type == '15'~ '11',
    traffic_type == '16'~ '11',
    traffic_type == '17'~ '11',
    traffic_type == '18'~ '11',
    traffic_type == '19'~ '11',
    traffic_type == '20'~ '15',
  )
)


#for browser
browser <- df$browser
hc <- hclust(dist(table(browser)))
plot(hc)

clusters_browser <- cutree(hc, h = 10)
clusters_browser

df<- df %>% mutate(
  grouped_browser = case_when(
    browser == '1'~ '1',
    browser == '2'~ '2',
    browser == '3'~ '3',
    browser == '4'~ '4',
    browser == '5'~ '5',
    browser == '6'~ '6',
    browser == '7'~ '7',
    browser == '8'~ '8',
    browser == '9'~ '7',
    browser == '10'~ '6',
    browser == '11'~ '7',
    browser == '12'~ '7',
    browser == '13'~ '7'
  )
) 


#for operating_systems
op <- df$operating_systems
hc <- hclust(dist(table(op)))
plot(hc)

clusters_op <- cutree(hc, h = 10)
clusters_op

df<- df %>% mutate(
  grouped_operating_systems = case_when(
    operating_systems == '1'~ '1',
    operating_systems == '2'~ '2',
    operating_systems == '3'~ '3',
    operating_systems == '4'~ '4',
    operating_systems == '5'~ '1',
    operating_systems == '6'~ '1',
    operating_systems == '7'~ '1',
    operating_systems == '8'~ '5'
  )
) 

df <- df %>%mutate(grouped_browser = as.factor(grouped_browser), grouped_traffic_type = as.factor(grouped_traffic_type), grouped_operating_systems = as.factor(grouped_operating_systems))

df <- df%>%select(purchase,visitor_type,grouped_traffic_type,region,grouped_browser, grouped_operating_systems,page_values, exit_rates, bounce_rates, special_day, weekend, month, product_related_duration, product_related, informational_duration, informational,administrative_duration, administrative)

```

Moreover, some variables are greatly overdispersed, so we decide to transform them to be able to construct better models. We apply both log transformations and square root transformation to solve this issue.

```{r adding variables, echo=FALSE, include = FALSE}
#log transformations
df <- df %>% mutate(
  log_exit = log(exit_rates +1 ),
  log_bounce = log(bounce_rates +1),
  log_administrative = log(administrative +1),
  log_admin_duration = log(administrative_duration +1),
  log_prod_related_duration = log(product_related_duration +1),
  log_prod_related = log(product_related +1),
  log_inf_duration = log(informational_duration+1),
  log_inf = log(informational_duration +1),
  log_page_values = log(page_values +1)
)

#sqrt transformation
df <- df %>% mutate(
  sqrt_exit = sqrt(exit_rates),
  sqrt_bounce = sqrt(bounce_rates),
  sqrt_administrative = sqrt(administrative),
  sqrt_time_admin = sqrt(administrative_duration),
  sqrt_time_duration = sqrt(product_related_duration)
)

#interaction terms
df <- df %>% mutate(
  inter_product = product_related * product_related_duration,
  inter_informational = informational * informational_duration,
  inter_admin = administrative * administrative_duration
)
```



# 3. Model selection 

```{r model building, echo=FALSE, include = FALSE}
m0_0 <- glm(purchase ~visitor_type + grouped_traffic_type + region + grouped_browser + grouped_operating_systems + page_values + exit_rates + bounce_rates + special_day + weekend + month + product_related_duration + product_related + informational_duration + informational + administrative_duration + administrative, family = 'binomial', data = df) #without the new included variables 

m0 <- glm(purchase ~., family = 'binomial', data = df) #with all the variables, including the new ones 

#to compare the first two models
summary(m0_0)
summary(m0)

m0_0$aic
m0$aic

m0_0$deviance
m0$deviance #adding the variables improved both the AIC and the deviance

#now I build a better model with the function stepAIC which will select the best model in terms of AIC
library('MASS')
#model <- stepAIC(m0,direction = c("both", "backward", "forward"), trace = FALSE)

model <- glm(purchase ~ visitor_type + grouped_traffic_type + 
    page_values + exit_rates + month + product_related_duration + 
    administrative + sqrt_exit + sqrt_bounce + sqrt_administrative + 
    sqrt_time_duration, family = "binomial", data =df)#this is the model given by stepAIC but as it's very long, I include it here directly
summary(model)

#to see if the variables selected are statistically significant
Anova(model, type = 'II', test ='LR') #all of them are significant
Anova(m0, type = 'II', test ='LR') #most of them are not significant

#trying to add some variables since m0 seems better
improved_model <- glm(purchase ~ visitor_type + grouped_traffic_type + 
    page_values + exit_rates + bounce_rates + month + product_related_duration + 
    administrative + log_admin_duration +log_prod_related_duration + log_page_values + sqrt_exit + sqrt_bounce + sqrt_administrative + 
    sqrt_time_duration, family = "binomial", data =df)
summary(improved_model)
Anova(improved_model, type = 'II', test ='LR') #sqrt_administrative is not significant

#by removing non significative variables one by one, I obtain the final model below
improved_model_2 <- glm(purchase ~ visitor_type + grouped_traffic_type + 
    page_values + exit_rates + bounce_rates + month + product_related_duration + 
    administrative +log_prod_related_duration + log_page_values + sqrt_exit + sqrt_bounce  + 
    sqrt_time_duration, family = "binomial", data =df)
summary(improved_model_2)
anova_table <- Anova(improved_model_2, type = 'II', test ='LR') #with this one all the variables are significative under the 5%

#odds ratio and confidence intervals
table_results_OR <- exp(cbind(OR = coef(improved_model_2), confint(improved_model_2)))

```

To build the model, I start by computing the full model without the added variables and compared it to the one with added variables to assess their relevance. The model with added variables has a smaller AIC (`r round(m0$aic, digits =0)` compared to `r round(m0_0$aic, digits=0)`) as well as a smaller deviance (`r round(m0$deviance, digits=0)` compared to `r round(m0_0$deviance, digits=0)`) which gives confidence in those new variables.

Then, I used the function *stepAIC* of the MASS package to do AIC-based model selection. This creates a basis model that I then improve by looking at the significance of the variables with the *Anova* command. This enabled me to build an improved model by adding variables one by one and simultaneously testing their significance. The final model includes the variables: the visitor type, the traffic type, the page values and its log, the exit rates and their square root, the bounce rates and their square root, the session month, the time spent looking at product-related information and its log and square root, the number of administrative pages looked at. They are all significant at the 5% level and most of them even at the below 0.1% level which gives confidence in the model built. The AIC of our final model is  `r round(improved_model_2$aic, digits=0)` and the deviance is `r round(improved_model$deviance, digits=0)`. 


```{r, echo=FALSE, include = FALSE}
#Summary of the final model
summary(improved_model_2)
```


```{r, echo=FALSE, include = FALSE}
#Odds ratio and confidence intervals
table_results_OR
```

The table below reports the three most practically significant variables (in terms of odds ratio) and their confidence interval.

|                    | OR       | 2.5%     | 97.5%       | 
|--------------------|----------|----------|-------------|
| bounce rates       | 9.16e+08 | 1.05e+01 | 2.58e+16    | 
| sqrt(exit rates)   | 5.23e+03 | 2.68e+01 | 1.15e+06    | 
| log(page values)   | 3.73     | 3.47     | 4.01        | 

They are statistically significant (with the Type II test with Anova and because 0 doesn't belong to the confidence interval). They are also practically significant because their odds ratio are greater than 1. Half of variables have odds ratio greater than 1 in the overall table and the rest mostly belongs to [0.2, 0.9]. Only the untransformed exit rate variable doesn't seem practically significant even though it is statistically significant, since the odds ratio associated is of order $10^{-18}$. The fact that the model also contains its square root captures most of the effect of the variable.

```{r, echo=FALSE, include= FALSE}
#Anova of the final model
anova_table
```

# 4. Model diagnostics
*Figure 2* shows the diagnostics of the model. On the upper left panel, one can see the characteristic two-bands pattern associated with logisitic regressions. There are several visible outliers that appear to be influential on the model as identified in the *scale-location* and *residuals vs leverage panels*. The normal QQplot for the logistic regression also identifies some outliers in the upper tail.

```{r, fig.align="center", fig.cap="Figure 2 : Diagnostics"}
par(mfrow=c(2,2))
plot(improved_model_2)
```

# 5. Model comparison 
In this section, I compare the final model to the initial models to see to what extent the work on the base helped us build a better model. The red curve represents the initial model without the added variables (ie the log and sqrt transormations). The black curve represents the one built with all the variables of the data set. Finally, the blue curve represents the model resulting from the *stepAIC* function, and the green curve represents the final model. The AUC that is plotted is the one calculated in the sample for the final model. 

The green one appears to really improve the model compared to the one built only by the *stepAIC* function. Transforming variables also clearly improves the ROC curve and thus the model.


```{r, fig.align="center", fig.cap="Figure 3 : ROC curves : initial model without added variables (red), model with all the variables (black), model with only variable selection (blue), final model (green)"}
library(pROC)
invisible(plot(roc(df$purchase,
                   fitted(m0_0)),
               col = "red", 
               print.auc = F,
               main = "ROC curves"))
invisible(plot(roc(df$purchase,
                   fitted(model)),
               print.auc = F, 
               col = "blue", 
               add = T))
invisible(plot(roc(df$purchase,
                   fitted(m0)),
               print.auc = F, 
               col = "black", 
               add = T))
invisible(plot(roc(df$purchase,
                   fitted(improved_model_2)),
               print.auc = T, 
               col = "green", 
               add = T))

legend("bottomright",legend=c("Initial model without added variables", "Model with only variable selection", "Model with all the variables", "Final model" ),
       col=c("red", "blue", "black", "green"), lty=1, cex=0.8)
```

```{r, echo=FALSE}
#code provided
library(pROC)
AUC_eval <- function(gmodel,Data){
set.seed(517)
Folds <- matrix(sample(1:dim(Data)[1]), ncol=5)
AUC <- rep(0,5)
for(k in 1:5){
train <- Data[-Folds[,k],]
test <- Data[Folds[,k],]
my_gm <- glm(gmodel$formula, family="binomial", data=train)
test_pred <- predict(my_gm, newdata = test, type="response")
AUC[k] <- auc(test$purchase,test_pred)
}
return(mean(AUC))
}


auc_m0 <- AUC_eval(m0,df)
auc_m0_0 <- AUC_eval(m0_0, df)
auc_model <- AUC_eval(model,df)
auc_improved_model <- AUC_eval(improved_model,df)
auc_improved_model_2 <- AUC_eval(improved_model_2,df)

```

By denoting by model0 the basis model without added variables, model1 the model with all the added variables, model2 the one obtained with *stepAIC* and model3 the final model, the performance results are as follows :  

|                    | model0 | model1 | model2 | model3 |
|--------------------|--------|--------|--------|--------|
| AIC                | 7167   | 6078   | 7094   | 6042   |
| AUC                | 0.88   | 0.911  | 0.889  | 0.913  |
| Residuals deviance | 7059   | 5938   | 7030   | 5975   |


# 6. Discussion
In the final model I built, all the variables are significant at the 5% level. All the indicators (AIC, AUC, and residuals deviance) are improved compared to the other models which gives confidence in the work done. However, as showed in Figure1, there are some influential outliers which could be removed from the data set in order to refit the model and see if it improved. Due to the limited time, this is not done in this project.

Another thing to consider is the practical relevance of this model. The code enables the reader to display the odds-ratios and their confidence intervals in order to further analyze the model. 

Finally, we clustered some variable levels in order not to have levels with few data, but the model would probably be more accurate if we didn't merge those levels but instead collect more data. 


# References
[1] https://cmr.berkeley.edu/2018/04/facebook-ads/