r <- runif(int_size[i], min=df$startpoint[i], max = df$endpoint[i])
X <- append(X, r)
}
#Initialisation of the EM algorithm
p_init <- 0.5
mu1_init <- 0.25
mu2_init <- 0.75
sigma1_init <- 0.25
sigma2_init <- 0.5
#function to estimate the parameters
estimate <- function(X, p_init, mu1_init, mu2_init, sigma1_init, sigma2_init){
Y <- numeric(length = length(X))
for (i in 1:length(X)){
if (X[i]>0){
Y[i] <- log(X[i])}}
N = length(X)
#criterion of convergence : epsilon
epsilon = 0.001
k=0
err = 20000 #error to which we will compare epsilon
old_likelihood <- 0
new_likelihood <- 0
p_new <- numeric(length=N)
#I put a limit of k interations to have a faster algorithm (especially useful in the Bootstrap algorithm)
while (err>epsilon & k<20){
#log likelihood computation
for (i in 1:length(X)){
old_likelihood <- old_likelihood + bilognorm(X[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
old_likelihood <- log(old_likelihood)
#new parameters
f_theta <- numeric(length(X))
gamma<- numeric(length(X))
for(i in 1:length(X)){
f_theta[i] <- bilognorm(X[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)
if(f_theta[i]>0){
gamma[i] <- p_init*lognormal(X[i], mu1_init, sigma1_init)/f_theta[i]}else{gamma[i]<-1}}
s <- sum(gamma)
p_new <- s/N
mu_1_new <- sum(Y*gamma)/s
mu_2_new <- sum(Y*(1-gamma))/(N-s)
s1 <- sum(gamma*(Y - mu1_init)**2)
s2 <- sum((1-gamma)*(Y - mu2_init)**2)
sigma1_new <- sqrt(s1/s)
sigma2_new <- sqrt(s2/(N-s))
#new log likelihood computation
for (i in 1:length(X)){
new_likelihood <- new_likelihood + bilognorm(X[i], mu_1_new, mu_2_new, sigma1_new, sigma2_new, p_new)}
new_likelihood <- log(new_likelihood)
#k represents the number of iterations before convergence
k = k+1
#err is the error
err = abs(new_likelihood- old_likelihood)
#new parameters
mu1_init <- mu_1_new
mu2_init <- mu_2_new
sigma1_init <- sigma1_new
sigma2_init <- sigma2_new
p_init <- p_new
#I put the likelihood at 0 to be able to compute them again
old_likelihood <- 0
new_likelihood <- 0
}
return(c(mu1_init, mu2_init, sigma1_init, sigma2_init, p_init))}
param <- estimate(X = X, p_init = p_init, mu1_init = mu1_init, mu2_init = mu2_init, sigma1_init = sigma1_init, sigma2_init = sigma2_init )
#the new parameters(estimated with EM)
mu1_init <- param[1]
mu2_init <- param[2]
sigma1_init <- param[3]
sigma2_init <- param[4]
p_init <- param[5]
#to plot
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Fitted distribution and real data', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#values I obtained and that I want to optimize
mu1 <- mu1_init
mu2 <- mu2_init
sigma1 <- sigma1_init
sigma2 <- sigma2_init
p <- p_init
epsilon = 0.05
par(mfrow = c(2,3))
#graph1
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 1', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph2
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init+epsilon, mu2_init+epsilon, sigma1_init+epsilon, sigma2_init+epsilon, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 2', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph3
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init-epsilon, mu2_init-epsilon, sigma1_init-epsilon, sigma2_init-epsilon, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 3', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph4
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init-epsilon, mu2_init+epsilon, sigma1_init+epsilon, sigma2_init+epsilon, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 4', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph5
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init+epsilon, mu2_init-epsilon, sigma1_init, sigma2_init, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 5', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph6
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init-epsilon, mu2_init+epsilon, sigma1_init, sigma2_init, p_init+epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 6', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
mixnorm <- function(param, X){
return(p=param[5]*plnorm(X, param[1], param[3])+(1-param[5])*plnorm(X, param[2], param[4]))
} #cdf mixture
#log likelihood to optimize
log_likelihood <- function(param){
res <- 0
for(i in 1:52){
res <- res + int_size[i]*log(mixnorm(param, df$endpoint[i]) - mixnorm(param, df$startpoint[i]))}
return(-res)
}
#old parameters
param <- c(mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)
#new optimized parameters
opt_param <- optim(par = param, fn = log_likelihood, gr=NULL)
#to plot
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
to_plot_z <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)
to_plot_z[i]<- bilognorm(to_plot_x[i], opt_param$par[1], opt_param$par[2], opt_param$par[3], opt_param$par[4], opt_param$par[5])}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Comparison of the models', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
lines(to_plot_x, to_plot_z, type = 'l', col='blue')
#compute the T stat
T_stat <- function(xn, mu1, mu2, sigma1, sigma2,p){
F_N <- ecdf(xn) #the ecdf of our sample
n = length(xn) #size of the sample
#evaluate_diff <- runif(n, min(xn), max(xn))
evaluate_diff <- xn
sample <- rep(0,n)
for (i in 1:n){
sample[i] <- bilognorm(evaluate_diff[i], mu1, mu2, sigma1, sigma2, p)
}
F_star <- ecdf(sample)
difabs <- abs(F_N(evaluate_diff) - F_star(evaluate_diff) )
return(max(difabs))
}
#parameters I estimated before
mu1_boot <- opt_param$par[1]
mu2_boot <- opt_param$par[2]
sigma1_boot <- opt_param$par[3]
sigma2_boot <- opt_param$par[4]
p_boot <- opt_param$par[5]
T_0 <- T_stat(X, mu1_boot, mu2_boot, sigma1_boot, sigma2_boot, p_boot) #ok
#Parametric Bootstrap
Bootstrap <- function(xn, T_0, mu1, mu2, sigma1, sigma2, p, B){
n = length(xn)
s <- 0
#Bootstrap
T_boot <- rep(NA, B)
x_resamples <- matrix(NA, nrow = B, ncol = n) #to put our resamples
for (i in 1:B) {
x_resamples[i,] <- sample(xn, replace = TRUE)
}
for(i in 1:B){
param <- estimate(x_resamples[i,], p, mu1, mu2, sigma1, sigma2)
mu1_estim <- param[1]
mu2_estim <- param[2]
sigma1_estim <- param[3]
sigma2_estim <- param[4]
p_estim <- param[5]
T_boot[i] <- T_stat(x_resamples[i,], mu1_estim, mu2_estim, sigma1_estim, sigma2_estim, p_estim)
}
for (i in 1:length(T_boot)){
if (T_boot[i]>T_0){
s <- s+1
}
}
return((1/(B+1))*(s))
}
#p value
b <- Bootstrap(X, T_0, mu1, mu2, sigma1, sigma2, p, 10)
b
View(bilognorm)
View(lognormal)
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
lapply(c("dplyr","chron","ggplot2","tidyr","questionr","survival","forcats","tidyselect",
"data.table","table1","lubridate", "ggpubr","viridis","finalfit","survminer",
"ggpubr", "ggthemes", "gridExtra", "rstatix","stringr",
"wesanderson","kableExtra", "naniar","boot","scales","ggsci", "stringr",
"Hmisc","DescTools","swimplot", 'stats', 'EnvStats'),
library, character.only=TRUE)
Sys.setlocale("LC_TIME", "English")
df <- read.csv("1_snow_particles.csv")
set.seed(435) #set the seed for reproducible results
df$binsize <- df$endpoint - df$startpoint #size of the intervals
plot(df$startpoint,(df$retained..../(100*df$binsize)), main ='Percentage of particles in each bin', xlab = 'Bin startpoint', ylab ='Proportion of particles(%)', type ='l', col='red')
#lognormal generates the lognormal density function
lognormal <- function(x, mu1, sigma1){
if (x>0){
return((1/x)*dnorm(log(x), mean=mu1, sd=sigma1))}
else{
return(0)
}
}
#bilognorm generates the mixture of two lognormal density function
bilognorm <- function(x, mu1, mu2, sigma1, sigma2, p) {
return(p*lognormal(x,mu1,sigma1)+(1-p)*lognormal(x,mu2,sigma2))
}
#simulate 705044 points
n_points <- trunc(df$particles.detected[1]) #total of points I will take
X <- c()
int_size <- numeric(length(df$retained....)) #number of points in each interval
for (i in 1:52){
int_size[i]<- df$retained....[i]*n_points/100
}
for (i in 1:52){
r <- runif(int_size[i], min=df$startpoint[i], max = df$endpoint[i])
X <- append(X, r)
}
#Initialisation of the EM algorithm
p_init <- 0.5
mu1_init <- 0.25
mu2_init <- 0.75
sigma1_init <- 0.25
sigma2_init <- 0.5
#function to estimate the parameters
estimate <- function(X, p_init, mu1_init, mu2_init, sigma1_init, sigma2_init){
Y <- numeric(length = length(X))
for (i in 1:length(X)){
if (X[i]>0){
Y[i] <- log(X[i])}}
N = length(X)
#criterion of convergence : epsilon
epsilon = 0.001
k=0
err = 20000 #error to which we will compare epsilon
old_likelihood <- 0
new_likelihood <- 0
p_new <- numeric(length=N)
#I put a limit of k interations to have a faster algorithm (especially useful in the Bootstrap algorithm)
while (err>epsilon & k<20){
#log likelihood computation
for (i in 1:length(X)){
old_likelihood <- old_likelihood + bilognorm(X[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
old_likelihood <- log(old_likelihood)
#new parameters
f_theta <- numeric(length(X))
gamma<- numeric(length(X))
for(i in 1:length(X)){
f_theta[i] <- bilognorm(X[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)
if(f_theta[i]>0){
gamma[i] <- p_init*lognormal(X[i], mu1_init, sigma1_init)/f_theta[i]}else{gamma[i]<-1}}
s <- sum(gamma)
p_new <- s/N
mu_1_new <- sum(Y*gamma)/s
mu_2_new <- sum(Y*(1-gamma))/(N-s)
s1 <- sum(gamma*(Y - mu1_init)**2)
s2 <- sum((1-gamma)*(Y - mu2_init)**2)
sigma1_new <- sqrt(s1/s)
sigma2_new <- sqrt(s2/(N-s))
#new log likelihood computation
for (i in 1:length(X)){
new_likelihood <- new_likelihood + bilognorm(X[i], mu_1_new, mu_2_new, sigma1_new, sigma2_new, p_new)}
new_likelihood <- log(new_likelihood)
#k represents the number of iterations before convergence
k = k+1
#err is the error
err = abs(new_likelihood- old_likelihood)
#new parameters
mu1_init <- mu_1_new
mu2_init <- mu_2_new
sigma1_init <- sigma1_new
sigma2_init <- sigma2_new
p_init <- p_new
#I put the likelihood at 0 to be able to compute them again
old_likelihood <- 0
new_likelihood <- 0
}
return(c(mu1_init, mu2_init, sigma1_init, sigma2_init, p_init))}
param <- estimate(X = X, p_init = p_init, mu1_init = mu1_init, mu2_init = mu2_init, sigma1_init = sigma1_init, sigma2_init = sigma2_init )
#the new parameters(estimated with EM)
mu1_init <- param[1]
mu2_init <- param[2]
sigma1_init <- param[3]
sigma2_init <- param[4]
p_init <- param[5]
#to plot
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Fitted distribution and real data', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#values I obtained and that I want to optimize
mu1 <- mu1_init
mu2 <- mu2_init
sigma1 <- sigma1_init
sigma2 <- sigma2_init
p <- p_init
epsilon = 0.05
par(mfrow = c(2,3))
#graph1
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init, mu2_init, sigma1_init, sigma2_init, p_init)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 1', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph2
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init+epsilon, mu2_init+epsilon, sigma1_init+epsilon, sigma2_init+epsilon, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 2', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph3
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i], mu1_init-epsilon, mu2_init-epsilon, sigma1_init-epsilon, sigma2_init-epsilon, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 3', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph4
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init-epsilon, mu2_init+epsilon, sigma1_init+epsilon, sigma2_init+epsilon, p_init-epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 4', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph5
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init+epsilon, mu2_init-epsilon, sigma1_init, sigma2_init, p_init+2*epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 5', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
#graph6
to_plot_x <- seq(0, 1.5, by=0.01)
to_plot_x <- append(to_plot_x, seq(1.5, 3, by=0.5))
to_plot_y <- numeric(length(to_plot_x))
for (i in 1:length(to_plot_x)){
to_plot_y[i] <- bilognorm(to_plot_x[i],mu1_init-epsilon, mu2_init+epsilon, sigma1_init, sigma2_init, p_init+epsilon)}
plot(df$startpoint,(df$retained..../(100*df$binsize)), col = 'red', type='l', main ='Distribution with setup 6', xlab ='Bin startpoint', ylab='Proportion of particles (%)')
lines(to_plot_x, to_plot_y, type='l')
setwd("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2")
load("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2/2_online_shopping.RData")
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
load("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2/2_online_shopping.RData")
data <- load("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2/2_online_shopping.RData")
data <- Data
Df<-Data
df<-Data
load("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2/2_online_shopping.RData")
df<-Data
View(df)
summary(df)
plot(df$Revenue)
summary(df)
#put everything in order (rename, type of var)
df <- df %>% mutate(
#from the e-commerce website
administrative = as.numeric(Administrative) %>% ff_label("Number of administrative pages visited"),
administrative_duration = as.numeric(Administrative_Duration)%>% ff_label("Time spent on administrative pages"),
informational = as.numeric(Informational) %>% ff_label("Number of informational-type pages visited"),
informational_duration =as.numeric(Informational_Duration) %>% ff_label("Time spent on informational-type pages"),
product_related = as.numeric(ProductRelated) %>% ff_label("Number of product related type pages visited"),
product_related_duration = as.numeric(ProductRelated_Duration)%>% ff_label(" Time spent on product related type pages"),
#derived from a date
month = as.factor(Month) %>% ff_label("Month of the session"),
weekend = as.factor(Weekend) %>% ff_label("Indicator of the session during a week-end"),
special_day = as.numeric(SpecialDay)%>% ff_label("Closeness to a Special day"),
#from google analytics
bounce_rates = as.numeric(BounceRates) %>% ff_label("Average bounce rate of pages visited"),
exit_rates = as.numeric(ExitRates) %>% ff_label('Average exit of pages visited'),
page_values= as.numeric(PageValues) %>% ff_label('Average page value of pages visited'),
operating_systems = as.factor(OperatingSystems)%>% ff_label("Operating systems of the user"),
browser = as.factor(Browser)%>% ff_label("Browser of the user"),
region = as.factor(Region) %>% ff_label("Geographic region"),
traffic_type = as.factor(TrafficType)%>% ff_label("Traffic type"),
visitor_type = as.factor(VisitorType)%>% ff_label("Visitor type"),
purchase = as.factor(Revenue)%>% ff_label("Indicator of a purchase made or not")
)
df
library('finalfit')
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
lapply(c("dplyr","chron","ggplot2","tidyr","questionr","survival","forcats","tidyselect",
"data.table","table1","lubridate", "ggpubr","viridis","finalfit","survminer",
"ggpubr", "ggthemes", "gridExtra", "rstatix","stringr",
"wesanderson","kableExtra", "naniar","boot","scales","ggsci", "stringr",
"Hmisc","DescTools","swimplot", 'stats', 'EnvStats', 'finalfit'),
library, character.only=TRUE)
Sys.setlocale("LC_TIME", "English")
load("C:/Users/candi/Desktop/ETUDES/EPFL1A/semestre 2/applied statistics/applied_stat_359523/project_2/2_online_shopping.RData")
set.seed(435) #set the seed for reproducible results
#put everything in order (rename, type of var)
df <- df %>% mutate(
#from the e-commerce website
administrative = as.numeric(Administrative) %>% ff_label("Number of administrative pages visited"),
administrative_duration = as.numeric(Administrative_Duration)%>% ff_label("Time spent on administrative pages"),
informational = as.numeric(Informational) %>% ff_label("Number of informational-type pages visited"),
informational_duration =as.numeric(Informational_Duration) %>% ff_label("Time spent on informational-type pages"),
product_related = as.numeric(ProductRelated) %>% ff_label("Number of product related type pages visited"),
product_related_duration = as.numeric(ProductRelated_Duration)%>% ff_label(" Time spent on product related type pages"),
#derived from a date
month = as.factor(Month) %>% ff_label("Month of the session"),
weekend = as.factor(Weekend) %>% ff_label("Indicator of the session during a week-end"),
special_day = as.numeric(SpecialDay)%>% ff_label("Closeness to a Special day"),
#from google analytics
bounce_rates = as.numeric(BounceRates) %>% ff_label("Average bounce rate of pages visited"),
exit_rates = as.numeric(ExitRates) %>% ff_label('Average exit of pages visited'),
page_values= as.numeric(PageValues) %>% ff_label('Average page value of pages visited'),
operating_systems = as.factor(OperatingSystems)%>% ff_label("Operating systems of the user"),
browser = as.factor(Browser)%>% ff_label("Browser of the user"),
region = as.factor(Region) %>% ff_label("Geographic region"),
traffic_type = as.factor(TrafficType)%>% ff_label("Traffic type"),
visitor_type = as.factor(VisitorType)%>% ff_label("Visitor type"),
purchase = as.factor(Revenue)%>% ff_label("Indicator of a purchase made or not")
)
df <- df %>% select(purchase,visitor_type,traffic_type,region,browser, operating_systems,page_values, exit_rates, bounce_rates, special_day, weekend, month, product_related_duration, product_related, informational_duration, informational,administrative_duration, administrative)
df %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(purchase)) +
facet_wrap(~ key, scales = "free") +
geom_histogram()
library(purrr)
library(tidyr)
library(ggplot2)
df %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(purchase)) +
facet_wrap(~ key, scales = "free") +
geom_histogram()
df %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_histogram()
df %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_histogram()
longer <- df %>%
pivot_longer(c(-purchase)),
longer <- df %>%
pivot_longer(),
plot(df$purchase, df$visitor_type)
View(df)
plot(df$bounce_rates)
plot(df$bounce_rates, purchase)
plot(df$bounce_rates, df$purchase)
#descriptive statistics
sum(df$purchase)
#descriptive statistics
df$purchase
#descriptive statistics
sum(df$purchase==F)
#descriptive statistics
sum(df$purchase==F)/length(df$purchase)
#descriptive statistics
1 - sum(df$purchase==F)/length(df$purchase)
plot(df$region)
#how variables behave with respect to purchasing
ggplot(data = df, aes(x = value)) +
stat_density() +
facet_wrap(~variable, scales = "free")
#how variables behave with respect to purchasing
pairs(df)
df%>%group_by(purchase, visitor_type)
df%>%group_by(purchase, visitor_type)%>%ggplot(aes(x = ZONE, y =AFFLUENCE.RATIO)) + geom_boxplot() + xlab('Region') + ylab('Affluence ratio (%)')
df%>%group_by(purchase, visitor_type)%>%ggplot(aes(x = purchase, y =visitor_type)) + geom_boxplot()
df%>%group_by(purchase, visitor_type)%>%ggplot(aes(x = purchase, y =visitor_type)) + geom_bar()
df%>%group_by(purchase, visitor_type)%>%summarise(number=n()) %>% mutate(freq = 100*number / sum(number)) %>%
ggplot(aes(x=purchase, y=visitor_type )) + geom_bar(stat="identity")
df%>%group_by(purchase, visitor_type)%>%summarise(number=n()) %>% mutate(freq = 100*number / sum(number)) %>%
ggplot(aes(x=purchase, y=visitor_type )) + geom_bar(stat="identity")
